\chapter{Cognitive Load, Effects, Design, Measures, and L2 Links}\label{ch:cogload}

This chapter establishes the theoretical foundations of cognitive load theory (CLT) and reviews empirical evidence for its application to second language learning. Section~\ref{sec:definitions} defines cognitive load within a specific model of human cognitive architecture, distinguishes intrinsic, extraneous, and germane load, and traces how these distinctions generate classic instructional effects. Section~\ref{sec:consequences} examines behavioral signatures of cognitive load in L2 production and comprehension, connecting theoretical constructs to observable patterns in speech and reading. Section~\ref{sec:manipulations} reviews design principles for managing intrinsic demands, reducing extraneous demands, and fostering productive processing. Section~\ref{sec:verification} specifies the methodological approach to validating cognitive load manipulations, including subjective ratings, behavioral indices, and physiological measures. Section~\ref{sec:load-selfeff} examines the bidirectional relationship between cognitive load and self-efficacy, a motivational construct that shapes how learners allocate effort and interpret difficulty. Together, these sections provide the conceptual framework and empirical foundation for the studies reported in Chapters~3 through~11.

\section{Definitions, Scope, and History}\label{sec:definitions}

This section establishes terminology and scope. The following subsections specify the cognitive architecture on which CLT is built, define the three categories of cognitive load, and explain how classic instructional effects follow from these architectural commitments. Boundary conditions and common misclassifications are identified to ensure precise application, and implications for second language learning are outlined.

\subsection{Cognitive Load and Cognitive Architecture}\label{subsec:architecture}

Cognitive load theory (CLT) is grounded in a specific model of human cognitive architecture \parencite{sweller2019}. According to this model, new information must be temporarily held and processed in working memory, which is severely limited in both capacity and duration. In contrast, knowledge already organized in long-term memory can be accessed with minimal processing cost. This architectural distinction has direct instructional implications. Designs that respect working memory limits facilitate schema construction and automation in long-term memory \parencite{sweller2019}.

CLT focuses on culturally acquired, biologically secondary knowledge—such as reading, mathematics, and domain-specific concepts—that requires explicit instruction and for which working memory limitations are especially consequential \parencite{schnotz2007}. Within this framework, \textcite{sweller2010} defines cognitive load as the moment-to-moment demand imposed on working memory during learning activities.

A standard analytic tripartition distinguishes three categories by origin \parencite{sweller2010}. \textit{Intrinsic load} stems from the inherent complexity of what must be learned—specifically, the number of interacting elements that must be processed simultaneously. For example, understanding a simple sentence with a single clause imposes lower intrinsic load than understanding a sentence with multiple embedded clauses, because the latter requires coordinating more elements. \textit{Extraneous load} is caused by avoidable demands introduced by the way information or tasks are presented. For instance, presenting text and related diagrams in spatially separated locations forces learners to mentally integrate information across sources, consuming working memory resources without contributing to schema construction \parencite{ChandlerSweller1992}. \textit{Germane load} refers to the portion of working memory resources productively devoted to building and refining knowledge structures. Effective instruction minimizes extraneous load and manages intrinsic load to maximize capacity available for germane processing.

Central to these distinctions is the notion of element interactivity: material is simple when elements can be processed independently and complex when elements must be coordinated simultaneously \parencite{sweller2010}. Increases in the number and strength of such interactions raise intrinsic demands for a given level of prior knowledge. The same lens helps identify extraneous demands, because formats that force unnecessary coordination inflate interactivity without changing what must be learned. This architectural grounding motivates the instructional effects reviewed in the following subsection.

A complementary specification of memory subsystems clarifies why working memory limits constrain instruction. Classic work distinguishes a phonological loop for speech-based information and a visuospatial store for visual information, coordinated by a central executive \parencite{BaddeleyHitch1974,Baddeley2002}. Long-term memory is functionally unlimited, and learning is the formation and tuning of schemas that recode multiple elements as a single functional unit, thereby reducing experienced interactivity over time \parencite{sweller1994,paas2003}. As procedures consolidate, processing shifts from effortful, explicit control toward automaticity in which operations can be executed with minimal working memory cost \parencite{paas2003}.

In L2 contexts, this implies that fluent lexical access and morphosyntactic routines operate as schema-based chunks that free capacity for message planning and discourse integration. This architecture is foundational for the thesis: the phonological loop and central executive are the primary bottlenecks in L2 speaking (Studies~1--2), while the visuospatial store and central executive are the key constraints in L2 comprehension (Studies~3--5). These limits justify the interactivity manipulations in Experiment~1 and the format and pacing choices in Experiment~2. The next subsection shows how these architectural commitments generate classic format effects that guide design.

\subsection{Element Interactivity and Instructional Effects}\label{subsec:effects}

The development of Cognitive Load Theory was initially motivated by evidence that conventional problem-solving approaches impose high working memory demands. Specifically, means-ends analysis requires extensive search processes that consume substantial working memory resources \parencite{sweller1988}. Under these conditions, learners devote capacity to difference reduction and step selection rather than to noticing structure or forming schemas, which explains weak learning despite considerable effort \parencite{sweller1988,sweller2010}.

The formative response was to redesign activities to remove this unnecessary search so that remaining capacity could be invested in schema acquisition and automation. For example, goal-free problems minimize backward search, worked examples present solutions directly for study, and completion problems provide partial solutions that constrain search while still requiring essential processing \parencite{sweller2010,sweller2019}. Converging evidence came from format effects: physically or temporally integrating mutually referring sources (e.g., text and diagrams) was found to be superior to presenting them separately, just as removing redundant or duplicated information improved outcomes \parencite{chandler1991}. These effects follow from element interactivity as defined in Subsection~\ref{subsec:architecture}.

When text and diagrams that refer to one another are separated, learners must search for corresponding elements and hold partial results in working memory while integrating across sources. This imposes extraneous coordination that adds nothing to what must eventually be learned. Physically integrating the sources eliminates this avoidable search, freeing capacity for schema construction. Similarly, when the same information is presented redundantly in multiple formats (e.g., narration plus on-screen text that duplicates the narration), learners must reconcile the streams, again consuming capacity without advancing understanding. In this thesis, we cite the intrinsic–extraneous–germane triad for completeness, but we manipulate only intrinsic load (via element interactivity) while holding extraneous factors constant; we interpret “germane” as the allocation of freed capacity to intrinsic processing rather than as a separate, addable source.


The boundary between necessary and unnecessary coordination depends on what the learner already knows. For novices, integrated presentation reduces search and supports learning. For experts, the same integration can become redundant because schemas in long-term memory already link the elements, making external guidance superfluous \parencite{kalyuga2007}. This expertise-reversal effect is a central boundary condition, addressed in detail in Subsection~\ref{subsec:boundaries}. The next subsection specifies these boundaries and clarifies when classifications shift with learner knowledge.

\subsection{Breadth, Boundaries, and Distinctions}\label{subsec:boundaries}

While CLT aims to provide generalizable design principles, applying its core distinctions to specific instructional contexts requires careful justification. Intrinsic, extraneous, and germane demands cannot always be cleanly separated in theory or in practice, since the same feature may be necessary for learning in one context yet superfluous in another \parencite{schnotz2007}. Contemporary accounts emphasize that classifications shift with expertise and goals: a graphic that guides attention for novices can become unnecessary once relations are encoded in long-term memory, at which point it functions as an extraneous source of demand \parencite{sweller2010,sweller2019}.

A critical boundary condition is that optimal instructional formats vary with learner expertise \parencite{kalyuga2007}. Design features that support novices can become redundant or even counterproductive as learners gain knowledge. For example, a graphic that guides attention for novices may become superfluous once learners have encoded the relevant relations in long-term memory, at which point it imposes extraneous load \parencite{sweller2010}. In adult L2 instruction, this predicts that integrated supports such as glosses should benefit novices but may become redundant as learners internalize vocabulary mappings \parencite{Sweller2017TESL}. Empirically, both outcomes appear. High-knowledge readers can learn more from lower-cohesion materials because they supply bridging inferences, while low-knowledge readers benefit from increased cohesion—the classic reverse cohesion pattern \parencite{mcnamara1996are}. A broader expertise-reversal literature reports that guidance and scaffolds assist novices but can become neutral or counterproductive for knowledgeable readers, consistent with a shift in the optimal balance between externally provided structure and self-generated integration \parencite{tetzlaff2025}.

These constraints require specifying how a design changes coordination demands for particular learners (see Subsection~\ref{subsec:architecture} for definitions; see Section~\ref{sec:verification} for validation). The principle of expertise reversal is the central hypothesis tested in Study~4, which examines how domain expertise moderates the impact of linguistic complexity on L2 reading. By crossing domain expertise (history vs.\ science background) with linguistic complexity (simple vs.\ complex syntax) and analyzing position-anchored eye-movement measures in text, Study~4 tests whether domain knowledge buffers the processing costs of complex language.

\subsection{Consolidation, Replication, and Extensions}\label{subsec:consolidation}

Recent summaries portray CLT as consolidated and refined by replication work and by integration with compatible perspectives. Practical implications follow: manipulations should be justified in terms of predicted changes in element interactivity for a given population, measurement choices should be aligned with the architecture, and contrasts should remain close to the theory's mechanisms \parencite{sweller2019,chenpass2023}. Classic prescriptions remain warranted when their premises hold: physically or temporally integrating mutually referring sources is appropriate when learners would otherwise be forced into avoidable search and mapping, and removing duplicated but nonessential information is advisable when redundancy would squander capacity \parencite{chandler1991,sweller2010}. These prescriptions presume careful attention to expertise because guidance essential for novices can become redundant as knowledge grows, calling for adaptive fading or restructuring of supports \parencite{sweller2010,sweller2019}.

Recent work integrates CLT with motivational theories. From a self-determination perspective, instructional formats that reduce extraneous load and provide clear structure can be combined with autonomy support, yielding lower reported cognitive load and higher engagement \parencite{evans2024}. Reviews of digital and online learning likewise argue for balancing motivational affordances with cognitive constraints and for constructive alignment so that load is managed in service of targeted outcomes \parencite{skulmowski2023}.

Across these extensions, the unifying message is conservative and cumulative: treat the architecture as a constraint, articulate how a design changes coordination demands for specific learners, and evaluate outcomes that include both learning and motivational quality \parencite{sweller2019,sweller2023}. Applied summaries extend these mechanisms to L2 teaching, arguing that, for adult novices, explicit instruction and careful control of redundancy and split-attention are preferable to unguided immersion until schemas begin to consolidate \parencite{Sweller2017TESL}. The contrasts and measures in this thesis follow consolidated prescriptions on integration, redundancy, and segmentation, with expertise treated as a moderator.

\subsection{Implications for L2}\label{subsec:l2-preview}

Although CLT was shaped largely by research in mathematics and science, its architectural claims generalize to domains where biologically secondary knowledge must be learned through capacity-limited working memory \parencite{schnotz2007,sweller2019}. Two implications follow for second language contexts.

First, element interactivity is partly a function of prior knowledge and automation. When lexical access, morphosyntactic parsing, or discourse integration are not yet fluent, the same materials require coordinating more elements at once. By CLT's logic, this raises intrinsic demand for a given learner and makes design-induced coordination pressures more consequential \parencite{sweller2010,sweller2019}.

Second, expertise reversal is expected along proficiency gradients. Guidance that supports novices can become redundant or even disruptive as knowledge grows, because previously separate elements are chunked in long-term memory and no longer require the same working memory resources \parencite{sweller2010,sweller2019,sweller2023}. This preview frames later sections, which analyze L2 tasks through the lens of element interactivity and architectural alignment while considering the conditions under which added guidance shifts from helpful to redundant \parencite{sweller2010,sweller2023}.

Beyond linguistic proficiency, domain expertise also moderates processing demands in academic contexts. University students develop specialized reading strategies within their disciplines \parencite{shanahan2008teaching}. Disciplinary literacy research demonstrates that different academic domains emphasize distinct approaches to text comprehension, with each field developing domain-specific reading strategies and priorities \parencite{wineburg1991reading,goldman2002functional}. This disciplinary expertise predicts differential processing of domain-matched versus domain-mismatched materials, as tested in Studies~3--5.

Differences between phonological and visuospatial channels further imply that nonredundant modality can buffer coordination pressure in L2 tasks when streams are complementary and tightly aligned \parencite{mousavi1995,Baddeley2002}. A parallel implication, made explicit for adult L2 instruction, is that second language learning in adulthood constitutes biologically secondary knowledge and therefore depends on capacity-limited working memory and benefits from explicit guidance rather than unguided immersion at novice levels \parencite{Sweller2017TESL}. This framing clarifies why CLT's architecture and effects transfer to L2 contexts and why design features that reduce unnecessary coordination should be expected to matter in L2 classrooms.

The general complexity principles outlined above gain further nuance in Japanese, where the writing system supplies strong visual cues. The system exploits systematic mappings between script types and grammatical functions. Morphographic kanji encode content words, and phonographic kana mark grammatical morphemes \parencites{kajii2001eye,white2012eye}. This arrangement provides pre-lexical word-boundary cues that facilitate initial fixation targeting. At the same time, the system has vulnerabilities. When mixed-script text already provides segmentation cues, additional formatting changes such as inter-word spacing provide benefits only in all-kana contexts \parencite{sainio2007role}. Visual complexity within characters also matters: words containing high-stroke kanji are fixated more often and read more slowly than words with low-stroke kanji, even when lexical frequency is controlled \parencite{white2012eye}. These properties motivate the spatial indices used later, since visual cues and clause-final packaging in Japanese predict changes in the footprint of the scanpath under load. These implications motivate the spatial scanpath indices and the modality contrasts in Studies~3 to~5.


\section{Consequences of Cognitive Load}\label{sec:consequences}

Cognitive load manifests in observable behavioral patterns. The following subsections review empirical signatures of increased processing demand in production (Section~\ref{subsec:prod-sigs}) and comprehension (Section~\ref{subsec:comp-sigs}), connecting theoretical constructs to measurable indices.

\subsection{Production Signatures}\label{subsec:prod-sigs}

Under high task or presentation demands, speakers tend to shift resources away from syntactic elaboration or error monitoring to maintain fluency, or conversely slow their rate to preserve accuracy, producing reallocations summarized in second language research \parencite{housen2009}. Empirical studies of perceived fluency align with this account: temporal measures such as speech rate, phonation time ratio, and mean length of runs are strong predictors of raters' fluency judgments, indicating that when coordination costs increase, timing variables absorb the impact \parencite{kormos2004}. Monitoring is integral to online speech production; process-proximal indicators such as repetitions, false starts, and reformulations complement global fluency metrics by indexing control costs and time-gaining strategies under load \parencite{albarqi2022}.

Building on these signatures, task features modulate how attention is redistributed across CAF. Within the resource-directing versus resource-dispersing distinction, increasing resource-directing complexity is often associated with gains in accuracy and complexity, frequently with fluency costs, whereas tightening resource-dispersing constraints tends to depress performance unless support is provided \parencite{Robinson2005}. A limited-attention perspective likewise predicts trade-offs under higher conceptual demands, especially when learners must conceptualize new content while encoding it \parencite{skehan1997}. Recent syntheses report consistent increases in linguistic complexity when tasks include more elements and stronger reasoning demands, more variable effects on accuracy, and typical costs to fluency; consequently, sequencing rather than single-shot contrasts has become a central design focus \parencite{jin2025}.

Sequencing proposals such as SSARC—to stabilize, simplify, automatize, reconstruct, and complexify—make explicit commitments about ordering and expected outcomes over a syllabus \parencite{Robinson2005}. Experimental work on oral performance shows how sequencing interacts with load type. Using a resource-directing manipulation of the number of elements and a resource-dispersing manipulation of planning time, \textcite{chen2025} compared simple-to-complex and complex-to-simple sequences against task repetition. Complex-to-simple advantaged complexity and accuracy; simple-to-complex advantaged fluency. Both sequences exceeded pure repetition for syntactic complexity, and repetition favored lexical complexity and fluency. These patterns are consistent with the idea that conceptual difficulty can be increased to direct attention to form, provided that dispersing constraints are not tightened at the same time \parencite{Robinson2001,Robinson2005}.

Validation cautions remain important. Not all nominally complex tasks impose measurably higher load for a given population. A careful test of an elements manipulation found that only large increases in the number of interacting elements yielded differences on dual-task costs, duration estimates, and mental-effort ratings, with indications that proficiency moderates sensitivity \parencite{sasayama2016}.

Modality and individual differences further condition outcomes. When the same complexity manipulation is administered as speaking and as writing, complexity gains and accuracy costs can appear in both modes, yet baseline trade-offs differ. One study observed that speaking was more accurate but less fluent than writing and that working memory did not predict outcomes once complexity and modality were controlled \parencite{cho2018}. In L2 writing specifically, working memory shows limited direct effects on text-level performance once proficiency is taken into account, and proficiency often emerges as the more reliable predictor across simple and complex versions of the same task \parencite{manchon2023,kuiken2011}.

Classic dispersing supports such as pre-task planning can shift attention to form and buffer fluency costs under higher conceptual load, especially in speaking \parencite{ryu2018}. In practical terms, resource-directing manipulations (e.g., increasing reasoning demands) recruit attention to formulation, typically enhancing structural and lexical elaboration. In contrast, resource-dispersing manipulations (e.g., time pressure) heighten coordination demands, typically depressing temporal fluency \parencite{gilabert2007,albarqi2022}. For example, adding elements or reasoning demands often yields more lexical and syntactic elaboration with fluency costs, while dual-tasking reliably reduces temporal fluency and increases repair behavior \parencite{gilabert2007,albarqi2022}. These signatures define the CAF indices and the listener feature set in Studies~1 and~2.

\subsection{Comprehension Signatures}\label{subsec:comp-sigs}

In comprehension, capacity constraints have well-documented ocular correlates: as task complexity or format-induced coordination increases, first-fixation duration and gaze duration rise on difficult regions, regressions become more frequent, and forward saccades shorten, reflecting effortful local integration rather than fluent parafoveal sampling \parencite{rayner1998}. Within CLT, the same phenomena are predicted by element interactivity: formats that inflate avoidable coordination—for example, mapping across separated sources or reconciling poorly aligned cues—raise extraneous demands and manifest in precisely these slowing and backtracking patterns \parencite{sweller2019}. Because these signatures unfold at different timescales, they can be used diagnostically to locate where capacity is being consumed. Early measures, such as first-fixation duration, are sensitive to recognition and initial lexical access, whereas later measures, such as total fixation time, fixation counts, and regressions, index integration and discourse-level binding. Increases in either set of indices reveal the stage at which coordination costs emerge and whether a manipulation primarily obstructs identification or subsequent unification \parencite{rayner1998}.

Understanding how linguistic complexity affects reading requires moving beyond traditional temporal measures to spatial indices that capture how attention is deployed across text. Metrics such as mean fixation duration, fixation count, and regression rate are canonical indices of cognitive load, revealing the timing of processing difficulty \parencite{rayner1998}. At the word level, measures such as gaze duration and skipping probability reveal how readers make moment-to-moment lexical processing decisions during reading. While these temporal measures are foundational, spatial measures reveal how attention is distributed across the text. Recent research shows that these spatial characteristics of eye-movement patterns provide converging evidence for processing difficulty \parencites[e.g.,][]{schad2012zoom,torres2021eye}. Radius of gyration—the root mean square distance of fixations from scanpath centroids—increases with linguistic complexity and correlates more strongly with self-reported effort than mean dwell time \parencite{schad2012zoom,Salvucci2000}.

A growing body of work also points to discourse-level complexity: texts that lack cohesive devices or exhibit unpredictable topic shifts further inflate fixation durations, and a recent corpus analysis showed that a combined index of lexical rarity, syntactic embedding, and cohesion accounts for roughly one third of variance in L2 eye-movement measures, outperforming traditional readability formulas \parencite{zhang2024modelling}. These effects generalize across typologically diverse languages; large cross-linguistic corpora confirm that dependency-distance penalties apply in head-initial, head-final, and mixed orders alike \parencite{Futrell2020}. In applied second-language contexts, methodological syntheses make the same distinction explicit, linking early and late eye-movement measures to hypothesized processing stages so that observed slowdowns can be attributed to specific coordination burdens rather than to generic difficulty \parencite{GodfroidWinke2019}.

Complementary spatial measures reach similar conclusions. Convex hull area—the polygon encompassing all fixations—correlates with readability measures across different text types \parencite{torres2021eye}. Electrophysiological studies show that processing long-distance dependencies is associated with a P600 component, indicating increased syntactic integration costs \parencite{fiebach2002wh}. Computational models that incorporate parallel word processing and continuous attentional gradients reproduce these patterns by modeling how processing difficulty broadens attentional gradients and suppresses forward saccade generation \parencite{engbert2002dynamical,engbert2005swift,schad2012zoom}. Including spatial dispersion alongside timing measures therefore strengthens inferences about complexity effects.

In the visual world paradigm, listeners use verb semantics and real-world constraints to anticipate upcoming referents, often launching saccades to a target object before it is mentioned; the classic finding that \textit{eat} triggers anticipatory looks to an edible item exemplifies incremental prediction under minimal presentation costs \parencite{altmann1999incremental}. Reviews emphasize that fixations reflect integration of linguistic and visual information in real time, hence they are suited to test how load and context shape prediction during comprehension \parencite{huettig2011using}. For late L2 learners, anticipatory behavior can be reduced or delayed relative to native speakers, a difference that arises from frequency biases, competition, and representation quality rather than from a distinct processing architecture \parencite{kaan2014predictive}.

At the predictive processing level, visual world paradigms reveal that L2 learners often fail to use morphosyntactic cues predictively. For instance, one study showed that while native Japanese listeners used a nominative-dative sequence to launch anticipatory eye movements to a theme object before it was mentioned, English-speaking learners of Japanese did not \parencite{mitsugi2016use}. This suggests that the L2 learners did not use case-marker information to generate predictions about upcoming verb arguments. Building on this, \textcite{mitsugi2017incremental} showed that this deficit extends to voice prediction; in a similar visual world study, native listeners exploited the same case cues to anticipate a passive verb, whereas English-speaking learners did not shift their gaze until the voice morphology surfaced. Flexible word order creates additional processing vulnerabilities. Japanese permits object fronting and scrambling, which amplifies dependency distances and forces readers to maintain displaced constituents in working memory. In native speakers, eye tracking reveals disproportionate integration costs at clause-final verbs and increased regressions to case particles when non-canonical orders increase \parencite{ueno2008relative,tamaoka2019eye}. Linguistically complex passages containing multiple embedded structures therefore predict both heightened particle rereading and more dispersed fixation patterns.

Listening research converges on the same conclusion through independent indices of effort. Pupil dilation scales with sentence intelligibility, increasing when the acoustic or linguistic signal is degraded, which indicates greater allocation of limited resources to maintain comprehension \parencite{zekveld2010pupil}. Broader frameworks of effortful listening formalize this relation as a balance between task demands, available capacity, and motivation, and they explain why listeners can report fatigue even when accuracy is maintained \parencite{pichora2016hearing}. Reviews of speech recognition in adverse conditions catalogue how noise, competing talkers, and cognitive load at the receiver jointly compromise segmentation and lexical access; they also motivate design choices such as pacing and redundancy control that reduce extraneous demand \parencite{mattys2012speech}. These online measures and models provide the needed bridge to the present thesis, allowing manipulations to be linked to specific stages of comprehension by predicting longer early measures when decoding is strained and longer late measures when integration fails, and by tying increases in pupil size to the extra effort required to sustain understanding under load \parencite{rayner1998,zekveld2010pupil}. These ocular measures serve as verification targets and process outcomes in Studies~4–5 (Study~3 analyzes subjective ratings, self-efficacy, and comprehension accuracy without eye tracking).


\section{How Tasks Manipulate Cognitive Load}\label{sec:manipulations}

Having reviewed behavioral signatures of cognitive load, this section examines design principles for managing processing demands. Three complementary approaches are distinguished: managing intrinsic load through sequencing and worked examples (Section~\ref{subsec:intrinsic}), reducing extraneous load through contiguity and modality effects (Section~\ref{subsec:extraneous}), and fostering germane processing through explanation prompts and subgoal labeling (Section~\ref{subsec:productive}). Boundary conditions are made explicit, including expertise reversal and limits imposed by temporal transience.

\subsection{Managing intrinsic load: sequencing and examples}\label{subsec:intrinsic}

Intrinsic load grows with element interactivity—that is, with the number of mutually dependent elements that must be coordinated at the same time by a learner with a given level of prior knowledge \parencite{sweller2010,swellerayres2011}. As knowledge increases and schemas form, many elements are recoded as a single functional unit, which lowers the experienced interactivity of the very same task \parencite{sweller1994}. Instruction manages this demand by altering what must be processed at once while preserving eventual exposure to the full set of relations.

Sequencing proceeds from lower to higher interactivity, isolates elements before integrating them, and schedules relational understanding for a later phase once prerequisites are secure \parencite{VanMerrienboer2004,jong2010}. A complementary progression begins with worked examples, shifts to completion problems, and culminates in independent problem-solving. This progression supports schema construction under high interactivity and yields transfer benefits when examples vary in surface features within a conceptual type \parencite{sweller1985,paas1994_2}.

A robust boundary condition is the expertise-reversal effect. Supports that assist novices can become redundant or disruptive as knowledge grows because they compete with established schema-based processing. This pattern motivates adaptive fading of guidance across acquisition \parencite{kalyuga2007,sweller2010}. Section~\ref{subsec:productive} specifies how to channel freed capacity once supports reduce coordination costs. These principles motivate the element-interactivity manipulation and planning-time control in Experiment~1.

\subsection{Reducing extraneous load: contiguity, modality, transience}\label{subsec:extraneous}

Extraneous load originates in how information is arranged and timed rather than in the conceptual relations to be mastered. Classic demonstrations show that spatial separation of mutually referring text and diagram forces unnecessary mapping and inflates avoidable coordination—the split-attention effect \parencite{ChandlerSweller1992}. In L2 settings, a concrete instance is vocabulary support: providing integrated translations adjacent to the target item removes avoidable search and mapping, whereas sending learners to a separate dictionary increases avoidable coordination \parencite{Sweller2017TESL}. Closely related formats that duplicate information can depress transfer through redundancy costs when learners must reconcile overlapping streams \parencite{Yeung1998}.

Designs that force learners to divide attention across mutually referring sources impose avoidable processing. Spatial and temporal contiguity—for example, placing text next to its diagram or synchronizing narration with a visual change—reduces the need for mental alignment and frees resources for learning \parencite{chandler1991,ginns2006}. Adding on-screen text that repeats a visual or narration can depress transfer because the extra words add processing without adding structure \parencite{mayerbove1996,chandler1991}.

Within this framework, modality functions as a format variable that can either reduce avoidable coordination or inflate it, depending on alignment and redundancy. Using modality to distribute complementary information across channels lowers extraneous load when the streams must be processed together and are not duplicative. In worked-example learning with diagrams, presenting statements auditorily alleviates split attention and improves learning—the modality effect \parencite{mousavi1995}.

Auditory information is transient, however. When verbal streams are long or densely structured, spoken text can overwhelm limited capacity and reverse the benefit. Shortening or chunking narration and coordinating it with visual segments mitigates this transient information cost \parencite{leahy2011,mayer2003}.

Because animations and lectures unfold over time, segmentation and simple pacing control redistribute processing across manageable units. Segmenting dynamic visuals into meaningful parts improves learning for novices, and signaling guides attention to critical elements and relations \parencite{spanjers2012,alpizar2020}. In second language multimedia contexts, captioning and subtitling generally enhance listening comprehension and vocabulary learning, with meta-analytic evidence showing reliable benefits across proficiency bands and test types \parencite{monteroperez2013}. Eye-tracking work indicates that caption use is shaped by script familiarity, content difficulty, and pacing. Co-timing caption units with prosodic and semantic boundaries and providing pause or replay help avoid overload \parencite{winke2013,mayer2003}. These principles guide the modality (text vs.\ video), captioning, and segmentation design choices in Experiment~2.

Evidence from pupillometry complements these format effects and clarifies why differences are often time-localized rather than uniform shifts. In minimal detection paradigms, audiovisual stimuli can produce superadditive pupil dilation relative to unimodal inputs \parencite{Rigato2016}. In continuous speech, acoustic challenge reliably enlarges dilation, and combined difficulties do not necessarily add beyond the acoustic burden, which shows that one stream can dominate allocation \parencite{Kadem2020}. Conflict and integration timing are visible in the pupil, with increases shortly after fixation on mismatching facial cues \parencite{AriasSarah2023}. Under high intelligibility, clearer speech can sometimes elicit slightly larger dilation than casual speech, plausibly reflecting deliberate allocation for maximal accuracy rather than difficulty per se \parencite{Mechtenberg2023}. Together with contiguity and redundancy principles, these results imply that aligned, nonredundant streams can reduce extraneous demand, while misalignment or duplication can raise it, and that resulting differences should appear as localized divergences over time. This expectation motivates trajectory-based analyses in Study~5.

\subsection{Fostering Productive Processing: Explanations and Subgoal Labels}\label{subsec:productive}

Productive processing denotes effort directed at constructing and organizing schemas. Process tracing and training studies agree that principle-based self-explanations during example study are a reliable mechanism that supports deep learning. Prompting learners to explain why a step is warranted and how it instantiates a principle improves transfer beyond gains in recall \parencite{chi1989}. Classroom studies further show that the frequency and quality of spontaneously produced explanations predict problem-solving even when time on task is controlled \parencite{renkl1997}.

At the level of example construction, design syntheses translate these mechanisms into features of examples that elicit constructive activity. Three levers repeatedly improve far transfer. First, pair each worked example with a matched practice item to encourage immediate application. Second, vary examples within a type to promote abstraction. Third, place rationales and operations in close proximity so that learners encounter structure where it is needed \parencite{atkinson2000}.

Subgoal labeling makes the structure explicit at a useful grain size. Grouping steps under compact, purpose-focused labels helps learners form reusable categories and adapt procedures to novel problems. Abstract, principle-oriented labels outperform superficial headings because they cue the organization that experts use when planning solutions \parencite{catrambone1998}.

Prompts should target quality rather than quantity. Learners who articulate principle-to-step links and anticipate upcoming moves gain more than those who merely paraphrase visible actions. High-quality, condition-focused explanations are the proximal predictor of success in longitudinal classroom work \parencite{renkl1997}.

At the lesson level, fading consolidates these gains. Moving from fully worked examples to partially completed solutions and then to independent generation invites a gradual shift from comprehension to production, especially when structural rationales are co-located with operations so that explanation and application proceed together \parencite{atkinson2000,chi1989}. Armed with these levers, the next section specifies how to verify that manipulations produce intended effects.



\section{Verifying Demand with Converging Evidence}\label{sec:verification}

This section provides operational rules for validating cognitive load manipulations; the causal stance was stated in Chapter~\ref{ch:intro-roadmap}. Recent studies have begun investigating whether task complexity can modulate the relationship between linguistic dimensions and listeners' judgments \parencite[e.g.,][]{Bergeron2017,crowther2018,fullana2024,SaitoLiu2022}. Nevertheless, as \textcite{sasayama2016} notes, designed differences between tasks of varying complexity do not always translate into actual cognitive differences. The present thesis therefore treats verification of cognitive demand as a prerequisite for interpretation and adopts a compact, theory-aligned measurement set in each strand.

\subsection{Task Complexity and Cognitive Load}

Robinson's Triadic Componential Framework distinguishes cognitive task complexity, task conditions, and task difficulty \parencite{Robinson2005}. Cognitive task complexity is specified through resource-directing dimensions (e.g., here-and-now vs.\ there-and-then, few vs.\ many elements, intentional reasoning) and resource-dispersing dimensions (e.g., planning time, number of steps, information organization). Task conditions are the circumstances of performance—for example, time pressure or concurrent activities. Task difficulty refers to perceived demand for particular learners.

Mapped to CLT, resource-directing manipulations raise intrinsic load when they require coordinating additional essential relations; resource-dispersing manipulations raise intrinsic load when they increase the number of mutually dependent elements processed at once; poor formats add extraneous load \parencite{ChandlerSweller1992,sweller2010,sweller2019}. Because element interactivity is defined relative to knowledge, expertise reversal is expected as schemas consolidate; guidance that once reduced coordination can become redundant \parencite{sweller2010}.

In this thesis, designed differences target intrinsic load via element interactivity while holding extraneous factors constant. Verification proceeds with a minimal, modality-appropriate set: in production, immediate effort ratings paired with a light secondary task; in comprehension, immediate effort ratings paired with eye movements. Outcome models are interpreted only when these checks confirm the intended increase in demand \parencite{paas1994_1,paas2003,brunken2002,Rayner2009}.

\subsection{Categories of Cognitive Load Measures}

Techniques for measuring task-induced cognitive load have been developed in cognitive psychology and multimedia learning. A common scheme classifies measures by objectivity and by causal relation: subjective or objective, direct or indirect \parencite{Brunken2003}.

First, subjective and indirect measures record invested mental effort. A standard approach asks participants to rate perceived effort on a nine-point scale from very low to very high immediately after a task \parencite{paas1994_1}. These ratings are efficient and sensitive to momentary strain; however, they require corroboration because low reported effort can reflect either genuinely low demand or a strategic response to high demand \parencite{Brunken2003,vanGogPaas2008}.

Second, subjective and direct measures target perceived difficulty or stress that is attributed to the materials or format. For example, participants can judge how easy or difficult computer-based instructions were to understand on a graded scale \parencite{Kalyuga1999}. The intended advantage is closer linkage to the load imposed by the materials.

Third, objective and indirect measures register behavioral or physiological consequences of demand. Behavioral indices include time on task and error patterns, which covary with cognitive complexity \parencite{Brunken2003}. Physiological indices include heart activity, pupil dilation, blink rate, eye movements and fixations, and skin conductance. These measures avoid subjective bias; at the same time they remain indirect, since factors can intervene between cognitive state and observed behavior \parencite{Brunken2003}.

Fourth, objective and direct measures aim to index capacity sharing itself. Neuroimaging can reveal task-related activation; however, links between activation and cognitive load during elaborated second language communication remain limited, and practical constraints are significant \parencite{Brunken2003}. For applied settings, the dual-task paradigm is recommended. A simple secondary probe draws on the same general pool of attention; when primary-task demand rises, responses to the probe slow or become less accurate \parencite{brunken2002}. Probe design matters for sensitivity. When the secondary task is too easy—for example, background color change—participants can maintain performance regardless of primary load. When selection demands are higher—for example, a letter color change in a defined region—differences between presentation modes and task versions are detected more reliably \parencite{Schoor2012}.

Within task-based language teaching, these families have been adapted to validate designed task complexity independently of linguistic performance. Self-rating questionnaires differentiate nominally simple from complex tasks, yet index perceived difficulty rather than design complexity \parencite{Robinson2001}. Introspective methods, including stimulated recall and interviews, show whether the more complex version actually recruited the intended reasoning and comparison operations even when perceived difficulty is similar \parencite{Kim_Payant_Pearson_2015}. Retrospective time estimation distinguishes complex from simple tasks in the predicted direction, with longer estimated than actual time under higher reasoning demands \parencite{Baralt_2013}. Eye tracking shows that higher reasoning demands elicit more and longer fixations than simpler counterparts; in the same studies, dual-task probes yield slower and less accurate responses under the more complex condition, providing a direct capacity-based check \parencite{revesz2014}.

Across categories, triangulation remains advisable for interpretability \parencite{Brunken2003,vanGogPaas2008}.

\subsection{Boundary Conditions and Validation Practices}

A recurring challenge is ensuring that designed task differences map onto cognitive demand in practice \parencite{revesz2014}. In studies linking listener judgments to linguistic dimensions, researchers frequently validate complexity with learners' self-ratings of difficulty or effort \parencite[e.g.,][]{crowther2018,fullana2024}. These subjective checks are informative but not sufficient on their own.

Evidence from capacity-based validations points to two boundary conditions. First, only relatively large increases in element interactivity reliably register across dual-task, timing, and self-rating measures: in monologic speaking, one- versus nine-element tasks diverged robustly, whereas intermediate steps were less consistently distinguished \parencite{sasayama2016}. Second, sensitivity can be task-type dependent: across map, seating, and car-accident tasks with graded element counts, demand increased with elements but not uniformly across formats \parencite{Lee2019}.

Subjective and objective indices can also differ in apparent magnitude. Self-ratings often yield larger effects than dual-task or RT-based measures, plausibly because perceptions can be swayed by salient but shallow features, whereas objective probes can miss subtler load if the secondary task is under-calibrated or if participants strategically disengage \parencite{sasayama2016}. The practical implication is to combine streams and to design secondary probes with sufficient selection demands and irregular timing while avoiding sensory interference with the primary task \parencite{Schoor2012,brunken2002}.

These boundary conditions motivate the multimethod approach adopted throughout this thesis: pairing subjective effort ratings with capacity-sharing indices in production studies (Studies~1--2) and with eye-movement and pupillometric indices in comprehension studies (Studies~3--5).

\subsection{Operationalization and Verification in This Thesis}

\textbf{Production (Studies~1--2).} After each trial, participants provide a single-item effort rating on the nine-point scale \parencite{paas1994_1,paas2003}. During speaking, a sparse and unpredictable secondary task samples spare capacity and is summarized as a speed-accuracy composite \parencite{vandierendonck2017}. The probe is practiced before measurement; timing is irregular to discourage strategic scheduling; sensory demands are chosen to avoid conflict with speech processing \parencite{brunken2002,Schoor2012}. Verification rule: effort ratings must increase in the predicted condition and the secondary-task composite must tighten in the same direction; production outcomes are interpreted only after demand has been verified \parencite{KormosDenes2004,revesz2014}.

\textbf{Comprehension (Studies~3--5).} All three comprehension studies draw on Experiment~2 but analyze different evidence streams. After each passage section, participants report experienced effort on a single-item scale; comprehension accuracy is assessed after learning.

Study~3 analyzes subjective cognitive load and self-efficacy ratings together with comprehension accuracy; eye movements are not analyzed in this study.

Study~4 analyzes eye movements in the text modality. Early measures (first-fixation duration, gaze duration) index recognition and initial lexical access. Late measures (total fixation time, regression count) index integration and discourse-level processing. A spatial index (scanpath regularity) captures how disrupted the fixation sequence becomes as difficulty increases \parencite{Rayner2009,VonderMalsburg2015}.

Study~5 models the complete pupil-diameter trajectory within each passage section across both text and video modalities, providing a time-resolved physiological index of moment-to-moment effort beyond aggregate eye-movement measures. Layout, font, and line length are fixed; calibration and exclusions follow established practice \parencite{GodfroidWinke2019}.

Analyses proceed only when demand has been verified: effort ratings must increase in the intended condition and at least one ocular index must move in the predicted direction, with interpretations kept proportionate where streams diverge \parencite{sasayama2016,Lee2019}.




\section{Cognitive Load and Self-Efficacy}\label{sec:load-selfeff}

Cognitive load and self-efficacy influence one another in both the short term and across longer spans. Recent syntheses integrate Cognitive Load Theory with models of expectancy, value, and cost by treating extraneous load as motivational cost and by documenting direct, task-specific effects of load on self-efficacy \parencite{Feldon2019}. Under this view, reducing avoidable coordination lowers perceived cost and protects concurrent efficacy, while calibrated intrinsic demand can raise expectancy when it produces visible learning benefits.

Self-efficacy—an individual's belief in their capability to perform a specific task—is among the most powerful motivational predictors of academic achievement \parencite{bandura_self-efficacy_1997}. Meta-analyses demonstrate that higher self-efficacy predicts greater persistence, more adaptive strategy use, and higher achievement across educational levels and domains \parencite{honicke_influence_2016,richardson_psychological_2012}.

Furthermore, longitudinal work has revealed a reciprocal relationship: performance success nurtures subsequent self-efficacy, while elevated self-efficacy feeds forward into future achievement, although performance tends to be the stronger driver \parencite{talsma_i_2018}.

Self-efficacy and cognitive load stand in a reciprocal relation that operates both immediately and over time. At the theoretical level, contemporary integrative accounts position experienced effort as the bridge between object-level processing and meta-level control; within this framework, self-efficacy functions simultaneously as an antecedent to cognitive processing and as an outcome that is updated by the experience of allocating effort under varying demands \parencite{de2020synthesizing}.

Recent integrative accounts have posited a bidirectional relationship between cognitive load and self-regulated learning. Although strategic behaviors such as planning, monitoring, and control can reduce extraneous load, they simultaneously impose metacognitive demands that consume the same cognitive resources they aim to liberate \parencite{de_bruin_synthesizing_2020,wang_how_2023}.

A central implication is a temporal dissociation: momentary processing strain can dampen confidence during learning, whereas successful engagement with calibrated complexity can, across longer spans, raise capability beliefs \parencite{seufert2020building}. While semester-long studies show that high cognitive load can depress self-efficacy \parencite{feldon_self-efficacy_2018,feldon_direct_2024}, their coarse timing obscures the rapid, moment-to-moment dynamics that better predict performance and can even invert over short intervals \parencite{vancouver_self-efficacy_2008,sitzmann_meta-analytic_2013,yeo_revisiting_2013}.

In L2 multimedia learning, these mechanisms operate at short timescales as well as across weeks. Momentary spikes in processing demand can precede short-term dips in self-efficacy, yet sustained success with calibrated complexity produces later gains in capability beliefs \parencite{feldon2018self,feldon2024direct}. The present thesis therefore samples effort and self-efficacy at section-level granularity where applicable, so that inferences respect the temporal profile of load and belief updating.

The following subsections synthesize empirical evidence for bidirectional influences between cognitive load and self-efficacy. Section~\ref{subsec:load-efficacy-links} reviews evidence across multiple time scales. Section~\ref{subsec:design-efficacy} examines instructional features that mediate or moderate this relationship. Section~\ref{subsec:meth-implications} outlines methodological implications for the present research.

\subsection{Mutual Influences Between Load and Self-Efficacy}\label{subsec:load-efficacy-links}

Experimental and longitudinal studies demonstrate that instructional load influences self-efficacy through pathways independent of achievement. For example, in an undergraduate science course, materials designed to reduce extraneous load produced larger pre-to-post gains in self-efficacy than comparison materials \parencite{feldon2018self}. These differences persisted after controlling for performance, suggesting that reduced cognitive burden directly influenced capability beliefs rather than operating solely through improved achievement. This temporal dissociation explains why confidence can dip while learners work through difficult content, yet strengthen after sustained, supported success with necessary complexity.

Converging evidence across domains reinforces the robustness of this pattern. Recent physiological studies reveal cognitive load spikes at precise moments: pupillometry shows sharp effort increases during speaker or accent switches in sentence comprehension \parencite{mclaughlin_sequence_2024}, while fixation-locked EEG with eye-tracking captures transient peaks from task-irrelevant decorative images \parencite{scharinger_task-irrelevant_2024}. Diary studies indicate that perceived difficulty spikes precede immediate self-efficacy dips, especially when baseline self-efficacy is low \parencite{stoten_metacognition_2019}.

In creative problem-solving, higher creative self-efficacy corresponds to lower experienced load, and competence-relevant feedback reduces load while sustaining performance; mediation analyses indicate that part of feedback's benefit flows through reduced processing strain \parencite{redifer2021self}. In complex skills acquisition, guided formats such as worked examples or structured multimedia reduce perceived effort for novices and are associated with higher self-efficacy than unguided problem-solving when task complexity is high \parencite{zheng2008effects}. Field studies in authentic learning settings show that academic self-efficacy tracks working-memory-relevant demands, though sample sizes are sometimes small and subgroup differences counsel caution \parencite{vasile2011academic}.

These micro-dynamics have cumulative consequences. Sustained high load leads to cognitive fatigue and performance declines \parencite{van_der_linden_mental_2003}. Conversely, optimally managed cognitive load fosters effective schema acquisition \parencite{sweller_cognitive_2011}, creating successful performance experiences that strengthen self-efficacy and adaptive strategy use \parencite{bandura_self-efficacy_1997,britner_sources_2006}.

Competing theoretical accounts exist: a proactive view posits that effective metacognitive monitoring guides regulation and performance \parencite{thiede_2003}, while a reactive view suggests that poor metacognition or maladaptive beliefs prompt disengagement, heightening overload vulnerability \parencite{schwonke_metacognitive_2015}. Collectively, these findings from creative cognition, multimedia learning, and classroom contexts converge on a consistent pattern: avoidable load depresses efficacy in the moment, whereas successful engagement with necessary load strengthens efficacy over time \parencite{feldon2018self,feldon2024direct}. The evidence provides strong support for a reactive pathway in which momentary increases in cognitive load are associated with subsequent declines in self-efficacy. This pattern has clear design implications: instruction should minimize avoidable effort spikes during initial phases, then use calibrated challenges that learners can master to support later efficacy growth.

\subsection{Instructional Mediators and Moderators of Load and Self-Efficacy}\label{subsec:design-efficacy}

Several instructional features systematically shape the relation between experienced cognitive load and self-efficacy by altering where effort is spent and how that effort is interpreted. Reducing extraneous processing demands through explicit task analysis and clear structure is associated with larger gains in self-efficacy than comparison instruction; these gains persist after accounting for achievement \parencite{feldon2018self}. In ordinary classroom implementations, a climate that combines clear structure with autonomy support corresponds to lower perceived extraneous and intrinsic load together with a stronger motivational environment that is conducive to efficacy growth \parencite{evans2024}.

Longitudinal analyses highlight the same temporal dissociation at different time scales. Within instructional episodes, higher experienced load coincides with lower concurrent self-efficacy. Across weeks, engagement with demanding work predicts later increases in self-efficacy even when learning is held constant, which suggests that necessary effort becomes credible evidence of capability once learners succeed under calibrated demands \parencite{feldon2024direct}. Sequencing of task complexity moderates this process. Progressions that begin at moderate difficulty and then increase complexity foster germane processing and meta-awareness more reliably than uniformly high difficulty, and these process changes co-occur with gains in interest and performance that support later willingness to invest effort when interactivity increases \parencite{zeitlhofer2024complexity}.

Feedback operates as a proximal mediator that links belief and burden during demanding phases. Competence-relevant feedback is associated with lower experienced load and sustained performance, providing immediate cues that stabilize capability judgments while learners work through complex material \parencite{redifer2021self}.

Models that integrate cognitive load with self-regulation clarify why these levers matter. Accounts that treat experienced effort as the bridge between processing and monitoring predict that learners require some bandwidth for regulation in order to interpret effort as informative rather than discouraging \parencite{de2020synthesizing}. Crucially, learners with stronger self-efficacy are typically more willing to expend the effort needed for self-regulated learning, thereby preventing overload; in contrast, learners with low self-efficacy often disengage, allowing intrinsic or extraneous load to overwhelm working memory \parencite{schwonke_metacognitive_2015}. Consistent with this prediction, interventions that keep difficulty near a moderate level elicit more adaptive strategy use than uniformly easy or uniformly hard tasks, and observed changes in strategy deployment are mediated by perceived load in an inverted-U-shaped pattern \parencite{seufert2024interplay}.

In combination, these findings indicate that reductions in avoidable demand, calibrated sequencing, competence-focused feedback, and preserved regulation bandwidth function as mediators and moderators of the link between cognitive load and self-efficacy rather than as independent instructional goals \parencite{evans2024}. Practically, reducing extraneous load functions as a cost reduction that preserves concurrent efficacy, while sequencing intrinsic demand provides the evidence for later efficacy growth \parencite{Feldon2019}.

\subsection{Methodological Implications for the Present Research}\label{subsec:meth-implications}

The literature reviewed above has several implications for the measurement approach adopted in this thesis. First, given that cognitive load and self-efficacy can fluctuate within a single instructional episode, both constructs are measured at section-level granularity rather than only at task completion \parencite{stoten_metacognition_2019}. This approach allows detection of transient spikes in processing demand and corresponding shifts in confidence that end-of-task ratings alone might miss \parencite{singer_reading_2017}.

Second, multiple indices are used to triangulate cognitive load: subjective effort ratings, behavioral measures (dual-task performance in production; eye movements in comprehension), and physiological measures (pupillometry in Study~5). This multimethod approach follows the principle that a manipulation is accepted as valid only when multiple streams converge \parencite{sasayama2016,Lee2019}.

Third, self-efficacy is assessed alongside cognitive load to test whether instructional manipulations influence motivation directly or primarily through their effects on processing demands. This allows examination of the temporal dynamics reviewed in Section~\ref{subsec:load-efficacy-links}: whether momentary increases in load correspond to concurrent decreases in self-efficacy, and whether sustained engagement with calibrated demands yields later efficacy gains.

Taken together, the chapter yields criteria that tie processing, learning, and motivation into a single design logic. These criteria inform the empirical choices that follow, including task sequences, measures of effort and performance, and the interpretation of proficiency-linked differences. In the experiments, this translates to clear structure, moderate initial difficulty, and competence-focused feedback during higher interactivity. The following chapter presents the design and validation of Experiment~1, which tests these principles in the context of L2 oral production under varying cognitive load.