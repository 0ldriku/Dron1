%************************************************
\chapter{Study 1: Prioritization in Production}\label{ch:study1}
%************************************************


\section{Introduction}



Experiment 1 (\autoref{ch:exp1-methods}) validated an element-interactivity manipulation for the oral task, establishing a reliable increase in cognitive load. Based on this foundation, Study 1 investigates how L2 speakers redistribute limited attention across complexity, accuracy, and fluency (CAF) under the validated load conditions. As detailed in \autoref{subsec:prod-sigs}, Skehan (\citeyear{Skehan2009}) and Robinson (\citeyear{Robinson2005}) both assume that bounded working memory constrains real-time speaking, but they make different predictions about task effects. Critically, most prior work has tested CAF indices separately, treating each outcome as independent and thereby obscuring the joint allocation structure that defines prioritization. 

The central research question is whether learners show coherent reallocation profiles under increased cognitive load. To address this, the present study first identifies representative indicators within each CAF construct through principal component analysis to avoid statistical redundancy. We then test for multivariate shifts to assess whether the overall production profile changes with cognitive load and proficiency. Together, this study provide a process-level account of prioritization that univariate tests cannot reveal, clarifying how learners manage competing demands in L2 speech production.


\section{Background}





\subsection{Prioritization and Fluctuations in CAF Under Cognitive Load}
As reviewed in \autoref{subsec:prod-sigs}, when cognitive load decreases, speakers reveal their priorities by reallocating freed resources to the dimensions they value most. Topic familiarity and exact task repetition reduce conceptualization costs and enable reallocations toward formulation and monitoring, producing gains that are greatest when initial topics are unfamiliar. \textcite{qiu2019} describes these patterns as fluctuations in CAF, where dimensions rise or plateau differentially as load changes. Planning and rehearsal produce parallel effects: load-relieving conditions (topic familiarity, repetition, structured planning) reveal latent priorities by showing which dimensions speakers protect once conceptualization pressure drops, allowing fluency to be maintained while attention shifts to accuracy and organization \parencite{qiu2019,stroud2019,ahmadian2015}. A complementary pathway to inferring priorities comes from structured online planning. Under supportive task structure, online planning elevates accuracy and complexity with mitigated fluency penalties, which implies that structure frees capacity for moment to moment control and lexical selection \parencite{ahmadian2015}. Together, these results portray prioritization as contingent on which resources are taxed, on how tasks are structured, and on which evaluative perspectives are applied.

\subsection{Methodological Limits of Univariate CAF Analyses}
Despite this process-level interdependence, much empirical work has analyzed CAF with separate univariate tests for each measure, a choice that can understate cross-dimension trade-offs and inflate Type I error when multiple indices are tested independently. For example, in an oral planning study, a series of one-way ANOVAs was run separately for complexity, accuracy, and fluency to compare planning and structure conditions, leading to condition-wise inferences on each dimension in isolation \parencite{ahmadian2012}. In L2 writing, the same approach is common. A study contrasting pretask versus online planning used a series of one-way ANOVAs for CAF and lexis, drawing dimension-specific conclusions without modeling their covariance \parencite{tabari2016}. Recent synchronous computer mediated work likewise relied on paired t-tests or Wilcoxon tests for each CAF index when contrasting simple versus complex versions of the same task \parencite{qian2023}. Similar per-index follow ups after an initial omnibus test are evident in recent speaking work \parencite{liuYeung2023}. Earlier task complexity work in writing reported separate analyses of variance for error subtypes and lexical frequency measures across complexity conditions, again treating outcomes as independent and obscuring the joint structure of CAF effects \parencite{kuiken2007}. To address these issues, the present study analyzes CAF in a multivariate framework that respects their covariance, allowing stronger inferences about prioritized trade-offs versus across the board gains. Accordingly, we model the CAF indicators jointly to recover the allocation vector under load, rather than testing each outcome in isolation.




\section{Research Question}

The literature on task complexity in L2 speech suggests that when cognitive load increases, speakers do not lose complexity, accuracy, and fluency in a uniform way, rather they reallocate attention to the features they treat as non negotiable. Building on this view, the present study asked a single question.

\begin{description}
    \item[RQ1:] How do L2 learners of Japanese redistribute limited attention across complexity, accuracy, fluency, and monitoring when cognitive load increases during monologic speech?
\end{description}

Building on the prioritization view outlined above, we hypothesize:

\begin{description}
    \item[H1:] When task complexity raises cognitive load, learners will protect form reliability and lexical precision, indicated by maintained accuracy and higher lexical density, and will accept costs in temporal and phrasal fluency, indicated by lower speech rate and fewer content words per AS-unit; this shift will be observable as a coherent multivariate change rather than as separate univariate decrements.
\end{description}




\section{Statistical Analysis}

\subsection{Choosing Representative Measures}
We began with fifteen indicators of speech performance (see \autoref{subsec:linguistic-dimensions}). However, many of these measures overlap. For example, different fluency measures often capture similar aspects of speaking speed. Using all fifteen would create two problems: statistical redundancy (multicollinearity) and difficulty interpreting results. To identify which measures capture distinct information, we ran principal component analyses (PCA) separately within each construct. This revealed the underlying structure: which measures group together and which capture independent dimensions. We then selected one representative indicator from each meaningful dimension, reducing the set to five key measures. For Fluency (eight indicators), the first component loaded on rate measures (for example, speech rate loading $=0.44$) and the second on pause timing (for example, mid-clause pause duration loading $=0.74$). For Complexity (five indicators), the first component indexed phrasal expansion (content words per AS-unit loading $=0.51$) and the second indexed lexical content (lexical density loading $=0.95$). For Accuracy (two indicators), a single component was dominated by the error indicator (error rate per AS-unit loading $=0.71$). Based on this structure, we selected five representative indicators, namely speech rate, mid-clause pause duration, content words per AS-unit, lexical density, and error rate per AS-unit. Table~\ref{tab:pca-select} summarizes the selection. Table \ref{tab:study1-descriptives} presents the descriptive statistics for the five selected indicators.


\begin{table}[h!]
\centering

\caption{Representative indicators selected by within construct PCA.}
\footnotesize
\label{tab:pca-select}
\begin{tabular}{llllS[table-format=1.3]}
\toprule
\textsc{Construct} & \textsc{Dimension} & \textsc{Selected indicator} & \textsc{PC} & \textsc{Loading} \\
\midrule
Fluency    & Speed      & Speech rate                   & PC1 & 0.442 \\
Fluency    & Breakdown  & Mid-clause pause duration (s) & PC2 & 0.735 \\
Complexity & Phrasal    & Content words per AS-unit     & PC1 & 0.510 \\
Complexity & Lexical    & Lexical density               & PC2 & 0.945 \\
Accuracy   & Errors     & Error rate (per AS-unit)      & PC1 & 0.707 \\
\bottomrule
\end{tabular}
\end{table}



\begin{table}[ht]
\centering
\caption{Descriptive statistics for five representative CAF indicators}
\footnotesize
\label{tab:study1-descriptives}
% Set S column formats to align all numbers
\begin{tabular}{l
                S[table-format=3.2]
                S[table-format=2.2]
                S[table-format=3.2]
                S[table-format=3.2]}
\toprule
& & & \multicolumn{2}{c}{$95\%$ CI} \\
\cline{4-5}
% Wrap S-column headers in {}
\textsc{Measures} & {$M$} & {$SD$} & {\textit{Lower}} & {\textit{Upper}} \\
\hline
% Use \multicolumn for category headers
\multicolumn{5}{l}{\textit{Low-complexity}} \\
Speech rate & 203.97 & 47.62 & 187.62 & 220.33 \\
Mid-clause pause duration & 0.69 & 0.22 & 0.61 & 0.76 \\
Number of content words per AS-unit & 6.35 & 1.83 & 5.72 & 6.98 \\
Lexical density & 46.33 & 3.65 & 45.08 & 47.58 \\
Error rate & 0.91 & 0.59 & 0.71 & 1.11 \\\midrule

\multicolumn{5}{l}{\textit{High-complexity}} \\

Speech rate & 185.37 & 49.68 & 168.31 & 202.44 \\
Mid-clause pause duration & 0.73 & 0.23 & 0.65 & 0.81 \\
Number of content words per AS-unit & 5.62 & 1.40 & 5.14 & 6.10 \\
Lexical density & 48.54 & 4.39 & 47.03 & 50.04 \\
Error rate & 0.68 & 0.53 & 0.50 & 0.86 \\



\bottomrule
\end{tabular}
\end{table}

\subsection{Multivariate Analysis of Production Outcomes}

We evaluated multivariate differences in production using permutational multivariate analysis of variance (PERMANOVA). A Euclidean distance matrix was computed from five z-standardized indicators: speech rate, mid-clause pause duration, content words per AS-unit, lexical density, and error rate (errors per AS-unit). The model included fixed effects of task complexity (low-complexity, high-complexity), proficiency (lower, middle, upper), and their interaction, and was fit with adonis2 using 999 unrestricted permutations and sequential sums of squares. Homogeneity of multivariate dispersion was assessed with betadisper, with both functions from the vegan package in R \parencite{vegan2025}. For significant main effects, we conducted post hoc pairwise PERMANOVAs with Bonferroni correction. For interpretive follow-up, we fit a linear discriminant analysis (LDA) with task complexity as the grouping factor and the five production indicators together with proficiency as predictors.


\section{Results}

\subsection{Multivariate Main Effects and Homogeneity}

The omnibus PERMANOVA revealed significant multivariate main effects for task complexity ($F(1, 64) = 3.05$, $R^2 = .040$, $p = .029$) and proficiency ($F(2, 64) = 3.68$, $R^2 = .097$, $p = .003$), with no interaction ($F(2, 64) = 0.75$, $R^2 = .020$, $p = .655$) (Table~\ref{tab:permanova}). Given the significant proficiency effect, follow-up pairwise comparisons indicated that only the lower versus upper contrast remained significant after Bonferroni correction ($p_{\text{adj}}  = .003$); lower versus middle ($p_{\text{adj}}  = .249$) and middle versus upper ($p = .555$) were not significant. We then conducted a permutational analysis of multivariate dispersions (PERMDISP) to test whether within-group multivariate spread (mean distance of observations to each group’s centroid in the five-indicator, z-scaled space) differed across groups. Dispersion did not differ by task complexity ($F(1, 68) = 0.04$, $p = .840$) or by proficiency ($F(2, 67) = 1.02$, $p = .370$); Figure~\ref{fig:disp-load} shows distances to centroids by task complexity. With dispersion homogeneous, the significant task complexity main effect reflects a location difference (centroids): the joint CAF profile differed between the low- and high-complexity tasks.


\begin{figure}[htb]
  \centering
  % Replace the filename below with your exported PERMDISP-by-load PDF (e.g., p2.pdf)
  \includegraphics[width=.9\linewidth]{Chapters/study1fig/p2.pdf}
  \caption{Homogeneity of dispersion (PERMDISP): distance to centroid by task complexity. Medians and IQRs overlap across conditions, consistent with the non-significant dispersion test.}
  \label{fig:disp-load}
\end{figure}


\begin{table}[htb]
\centering

\caption{PERMANOVA by terms on Euclidean distances of the five indicators (999 permutations).}
\footnotesize
\label{tab:permanova}
% Use 'S' columns for numbers and set their format
\begin{tabular}{l
                S[table-format=2.0]
                S[table-format=1.4]
                S[table-format=1.3]
                r}  % Use regular right-aligned column
\toprule
\textsc{Term} & {Df} & {$F$} & {$R^{2}$} & \multicolumn{1}{c}{$p$} \\  % Center the header
\midrule
Task complexity & 1 & 3.05 & 0.040 & $.029$ \\
Proficiency & 2 & 3.6806 & 0.097 & $.003$ \\
Task complexity $\times$ Proficiency & 2 & 0.75 & 0.020 & $.655$ \\
Residuals & 64 & & 0.843 & \\
Total & 69 & & 1.00 & \\
\bottomrule
\end{tabular}
\end{table}






\subsection{Discriminant Structure of Task Complexity}



As a descriptive follow-up to the task complexity effect, we fit an LDA with task complexity as the grouping factor and the five production indicators together with proficiency as predictors. Leave-one-out accuracy was 60\%, indicating modest separation between low- and high-complexity conditions. The coefficients (Table~\ref{tab:lda-coef}) showed positive weights for speech rate and content words per AS-unit and a negative weight for lexical density, with minimal contribution from mid-clause pause duration and error rate—consistent with costs to temporal/phrasal fluency and protection of lexical precision under higher load. Box’s M was not significant ($\chi^{2}(15) = 21.603$, $p = .119$), consistent with the LDA covariance assumption in this sample.









\begin{table}[ht]
\centering

\caption{Linear discriminant coefficients (LD1). Positive values indicate higher scores on the fluency and phrasal side of the discriminant.}
\footnotesize
\label{tab:lda-coef}
% Use 'S' column and set format for sign, 1 integer, 2 decimals
\begin{tabular}{l S[table-format=-1.2]}
\toprule
% Wrap S-column header in {}
\textsc{Predictor} & {LD1} \\
\midrule
Speech rate & 0.42 \\
Content words per AS-unit & 0.79 \\
Lexical density & -0.63 \\
Mid-clause pause duration (s) & -0.03 \\
Error rate (per AS-unit) & 0.07 \\
Proficiency (middle) & -0.78 \\
Proficiency (upper) & -1.49 \\
\bottomrule
\end{tabular}
\end{table}


\section{Discussion}



Our research question asked how L2 learners prioritize and trade off CAF as cognitive load increases. The multivariate results show a reliable, albeit small, shift in the joint CAF profile from low to high complexity, with no moderation by proficiency. Reading the PERMANOVA alongside the LDA, the pattern is clear: under higher load, learners prioritized lexical precision over phrasal elaboration and temporal speed—speech rate and content words per AS-unit declined, lexical density increased, and accuracy was maintained. With respect to H1, the data support a coherent multivariate shift under higher load, with costs in temporal and phrasal fluency and protection of lexical precision and form reliability; no task-complexity by proficiency interaction was observed.

This allocation pattern both supports and qualifies existing accounts. It confirms limited-capacity constraints in which dimensions compete for attention as demands rise \parencite{Skehan2009}, yet it departs from the common prediction that fluency is protected at the expense of complexity and accuracy. Instead, learners protected lexical precision and form reliability while accepting costs in temporal fluency and phrasal elaboration. We interpret this reversal as partly language-specific. In Japanese, obligatory function words (e.g., case particles, conjunctive particles, and auxiliary verbs) encode grammatical relations that English marks through word order; omitting or misusing particles obscures argument structure (who did what to whom), whereas English speakers can simplify syntax while preserving core message structure \parencite{makino1986}. When element interactivity increased, learners appear to have allocated resources to monitoring these morphosyntactic elements (consistent with maintained accuracy) and to lexical selection (higher lexical density), even at the cost of speed and phrasal packaging. Thus, obligatory morphosyntactic encoding creates a constraint that shifts allocation priorities under load.

Robinson’s (\citeyear{Robinson2005}) Cognition Hypothesis predicts that resource-directing manipulations can enhance complexity and accuracy despite fluency costs. The present results align on the fluency cost but show maintained—rather than enhanced—accuracy and a complexity dissociation: lexical density increased while phrasal elaboration declined. Framed within the resource-directing/resource-dispersing distinction \parencite{levkina2012}, our manipulation directed attention to lexical selection and form monitoring rather than to syntactic expansion, helping to explain mixed CAF outcomes across task types \parencite{chen2022}.

Proficiency explained additional variance independent of task complexity (lower versus upper differed), consistent with accounts in which greater proficiency automates lexical access and morphosyntactic routines, reducing experienced interactivity. The absence of a task complexity by proficiency interaction indicates that increasing element interactivity shifted CAF profiles in similar ways across proficiency strata rather than amplifying or reversing group differences.


\subsection{Limitations, Implications, and Future Directions}


Methodologically, we validated the designed difference in task complexity as cognitively consequential via converging manipulation checks (subjective difficulty/effort, secondary-task speed/accuracy), in line with recommendations that such validation underwrite causal claims about downstream CAF differences \parencite{revesz2014,Lee2019}. Modeling CAF in a multivariate framework respects their covariance and avoids the interpretive pitfalls of separate univariate tests that can obscure trade-offs and inflate Type I error \parencite{ahmadian2012,tabari2016,qian2023,liuYeung2023,kuiken2007}. 

Several limitations warrant consideration. First, the secondary task, while serving as a manipulation check, may have diverted participants' attentional resources and potentially affected speech production \parencite{fukuta2015}; future research should consider alternative validation methods that do not interfere with the primary task. Second, the small effect size and reliance on a single argumentative matching task with trimmed samples (analyzing only the initial 60 seconds) may not fully capture participants' oral performance or generalize across task types; more comprehensive samples and diverse task designs are needed. Third, our homogeneous participant group and the omission of some linguistic features (e.g., phonetic predictors) limit generalizability. 

Pedagogically, increasing element interactivity can be used to probe or train lexical precision while anticipating costs in speed and phrasal density, without a systematic increase in overt errorfulness. Theoretically, the results underscore that task-induced “complexity” shifts are not unitary: under higher cognitive load, lexical and phrasal dimensions can diverge, a pattern consistent with limited capacity accounts and complementary to resource-directing predictions when complexity is decomposed by facet \parencite{Skehan2009,Robinson2005,levkina2012}. Over longer spans, sustained exposure to resource-directing demands may yield developmental benefits in syntactic complexity and fluency despite short-term trade-offs, suggesting a potential pathway for instruction and assessment \parencite{gilabert2007,kim2017}.


\section{Conclusion}
The present study asked how L2 speakers of Japanese prioritize and trade off complexity, accuracy, and fluency as cognitive load increases. The multivariate analyses showed a reliable, although small, shift in the joint CAF profile under higher task complexity. Learners protected lexical precision and form reliability, indicated by maintained accuracy and increased lexical density, while accepting costs in temporal speed and phrasal elaboration, indicated by reduced speech rate and fewer content words per AS-unit. These reallocations were similar across proficiency strata, with overall level differences but no interaction with task complexity. In short, when demands rise, learners direct limited attention toward lexical selection and morphosyntactic monitoring, and they ease off speed and phrasal packaging. This pattern differs from predictions based on English-speaking contexts and may reflect Japanese-specific demands: obligatory function words that encode grammatical relationships create a constraint that shifts allocation priorities under load.



Methodologically, modeling CAF in a single multivariate framework recovered the allocation pattern that separate per-index tests might obscure. The design also incorporated independent validation of the complexity manipulation, which strengthens causal interpretation of downstream differences. At the same time, the effects were modest, the task type was narrow, and the productions were trimmed. Generality should be tested across genres, longer stretches of speech, and with richer process-proximal indicators such as repairs and repetitions.

For pedagogy and assessment, the results caution against treating complexity as a unitary outcome. Increases in element interactivity can pull lexical and phrasal dimensions in different directions, so tasks that aim to cultivate precise lexical choice may do so at the expense of speed and phrasal density, while not necessarily increasing overt errorfulness. This suggests two practical levers: use higher interactivity to probe or train lexical precision while explicitly supporting phrasal packaging, and evaluate speaking with composite profiles that respect trade offs rather than single indices in isolation.

Finally, these findings set up the next steps in the thesis. Subsequent studies examine whether analogous reallocations appear in comprehension. Together, this program moves from establishing allocation under load in production to linking performance profiles with evaluation.