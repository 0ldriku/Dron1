%************************************************
\chapter{Study 1: Prioritization in Production}\label{ch:study1}
%************************************************


\section{Introduction}
Cognitive load during task performance has long been implicated in how second language (L2) speakers distribute limited attentional resources across multiple performance demands. Within task based language teaching and assessment, this raises a core question for L2 Japanese speech production: when cognitive load rises, which dimensions of performance do speakers prioritize, and which do they sacrifice? Framed in the widely used CAF triad, the present study examines how incremental increases in cognitive load reallocate attention among CAF in L2 Japanese monologic speaking.


The study is motivated by converging evidence that specific manipulations of task complexity (resource directing versus resource dispersing), implementation variables (planning time, dual tasking), and knowledge conditions (topic familiarity, exact repetition) yield patterned redistributions across CAF rather than uniform decrements, and that these redistributions vary with task type, modality, and proficiency \parencite{chen2022}. This motivates treating CAF effects as principled reallocations of limited attentional resources, with consequences for production profiles and for how those profiles are evaluated.





This study contributes three advances. First, it uses the validated task-complexity contrast from Experiment 1 to support causal interpretation of performance differences. Second, it analyzes a set of CAF indicators in a single multivariate model, so reallocations can be interpreted at the profile level rather than measure by measure. Third, it identifies the production features that are most strongly protected when demand increases, which prepares the ground for the perception analysis in Study 2 (\autoref{ch:study2}).

\section{Background}





\subsection{Prioritization and Fluctuations in CAF under Cognitive Load}

Consistent with the load and release logic set out in \autoref{ch:intro-roadmap}, and with the consequences of cognitive load reviewed in \autoref{subsec:prod-sigs}, easing cognitive load makes visible the dimensions that speakers choose to prioritize. Topic familiarity and exact task repetition reduce conceptualization costs and enable reallocations toward formulation and monitoring, producing gains that are greatest when initial topics are unfamiliar. \textcite{qiu2019} describes these patterns as fluctuations in CAF, where dimensions rise or plateau differentially as load changes. Planning and rehearsal produce parallel effects: load-relieving conditions (topic familiarity, repetition, structured planning) reveal latent priorities by showing which dimensions speakers protect once conceptualization pressure drops, allowing fluency to be maintained while attention shifts to accuracy and organization \parencite{qiu2019,stroud2019,ahmadian2015}. A complementary pathway to inferring priorities comes from structured online planning. Under supportive task structure, online planning elevates accuracy and complexity with mitigated fluency penalties, which implies that structure frees capacity for moment to moment control and lexical selection \parencite{ahmadian2015}. Together, these results portray prioritization as contingent on which resources are taxed, on how tasks are structured, and on which evaluative perspectives are applied.

\subsection{Methodological Limits of Univariate CAF Analyses}
Despite this process-level interdependence, much empirical work has analyzed CAF with separate univariate tests for each measure, a choice that can understate cross-dimension trade-offs and inflate Type I error when multiple indices are tested independently. For example, in an oral planning study, a series of one-way ANOVAs was run separately for complexity, accuracy, and fluency to compare planning and structure conditions, leading to condition-wise inferences on each dimension in isolation \parencite{ahmadian2012}. In L2 writing, the same approach is common. A study contrasting pretask versus online planning used a series of one-way ANOVAs for CAF and lexis, drawing dimension-specific conclusions without modeling their covariance \parencite{tabari2016}. Recent synchronous computer mediated work likewise relied on paired t-tests or Wilcoxon tests for each CAF index when contrasting simple versus complex versions of the same task \parencite{qian2023}. Similar per-index follow ups after an initial omnibus test are evident in recent speaking work \parencite{liuYeung2023}. Earlier task complexity work in writing reported separate analyses of variance for error subtypes and lexical frequency measures across complexity conditions, again treating outcomes as independent and obscuring the joint structure of CAF effects \parencite{kuiken2007}. To address these issues, the present study analyzes CAF in a multivariate framework that respects their covariance, allowing stronger inferences about prioritized trade-offs versus across the board gains. Accordingly, we model the CAF indicators jointly to recover the allocation vector under load, rather than testing each outcome in isolation.




\section{Research Question}

The literature on task complexity in L2 speech suggests that when cognitive load increases, speakers do not lose complexity, accuracy, and fluency in a uniform way, rather they reallocate attention to the features they treat as non negotiable. Building on this view, the present study asked a single question.

\begin{description}
    \item[RQ1:] How do L2 learners of Japanese redistribute limited attention across complexity, accuracy, fluency, and monitoring when cognitive load increases during monologic speech?
\end{description}

Building on the prioritization view outlined above, we hypothesize:

\begin{description}
    \item[H1:] When task complexity raises cognitive load, learners will protect form reliability and lexical precision, indicated by maintained accuracy and higher lexical density, and will accept costs in temporal and phrasal fluency, indicated by lower speech rate and fewer content words per AS unit; this shift will be observable as a coherent multivariate change rather than as separate univariate decrements.
\end{description}




\section{Method}

\subsection{Dimensionality Reduction and Variable Selection}
To avoid multicollinearity and to select representative indicators, we ran principal component analyses (PCA) separately on standardized variables within the Fluency, Complexity, and Accuracy constructs. For Fluency (8 indicators), the first component loaded on rate measures (for example, speech rate loading $=0.44$) and the second on pause timing (for example, mid-clause pause duration loading $=0.74$). For Complexity (5 indicators), the first component indexed phrasal expansion (content words per AS-unit loading $=0.51$) and the second indexed lexical content (lexical density loading $=0.95$). For Accuracy (2 indicators), a single component was dominated by the error indicator (error rate per AS-unit loading $=0.71$). Based on this structure, we selected five representative indicators, namely speech rate, mid-clause pause duration, content words per AS-unit, lexical density, and error rate per AS-unit. Table~\ref{tab:pca-select} summarizes the selection. 


\begin{table}[h!]
\centering
\footnotesize
\caption{Representative indicators selected by within construct PCA.}
\label{tab:pca-select}
\begin{tabular}{llllS[table-format=1.3]}
\toprule
\textsc{Construct} & \textsc{Dimension} & \textsc{Selected indicator} & \textsc{PC} & \textsc{Loading} \\
\midrule
Fluency    & Speed      & Speech rate                   & PC1 & 0.442 \\
Fluency    & Breakdown  & Mid-clause pause duration (s) & PC2 & 0.735 \\
Complexity & Phrasal    & Content words per AS-unit     & PC1 & 0.510 \\
Complexity & Lexical    & Lexical density               & PC2 & 0.945 \\
Accuracy   & Errors     & Error rate (per AS-unit)      & PC1 & 0.707 \\
\bottomrule
\end{tabular}
\end{table}


\subsection{Statistical Analysis}

We evaluated multivariate differences in production using permutational multivariate analysis of variance (PERMANOVA). A Euclidean distance matrix was computed from five z-standardized indicators: speech rate, mid-clause pause duration, content words per AS-unit, lexical density, and error rate (errors per AS-unit). The model included fixed effects of task complexity (low-complexity, high-complexity), proficiency (lower, middle, upper), and their interaction, and was fit with `adonis2` using 999 unrestricted permutations and sequential sums of squares. Homogeneity of multivariate dispersion was assessed with `betadisper`, with both functions from the vegan package in R \parencite{vegan2025}. For significant main effects, we conducted post hoc pairwise PERMANOVAs with Bonferroni correction. For interpretive follow-up, we fit a linear discriminant analysis (LDA) with task complexity as the grouping factor and the five production indicators together with proficiency as predictors.


\section{Results}

\subsection{Multivariate Main Effects and Homogeneity}


The omnibus PERMANOVA revealed significant multivariate main effects for both task complexity ($F(1, 64) = 3.05$, $R^2 = .040$, $p = .029$) and proficiency ($F(2, 64) = 3.68$, $R^2 = .097$, $p = .003$), with no significant interaction ($F(2, 64) = 0.75$, $R^2 = .020$, $p = .655$) (Table~\ref{tab:permanova}). A visualization of the multivariate separation is provided by the Principal Coordinate Analysis (PCoA) ordination (Figure~\ref{fig:pcoa}), which shows partially overlapping but shifted centroids by task complexity. Dispersion diagnostics supported a location-based interpretation, task complexity, $F(1, 68) = 0.04$, $p = .840$, proficiency, $F(2, 67) = 1.02$, $p = .370$. Figure~\ref{fig:disp-load} focuses on the task-complexity factor.


\begin{table}[htbp]
\centering
\footnotesize
\caption{PERMANOVA by terms on Euclidean distances of the five indicators (999 permutations).}
\label{tab:permanova}
% Use 'S' columns for numbers and set their format
\begin{tabular}{l
                S[table-format=2.0]
                S[table-format=1.4]
                S[table-format=1.3]
                r}  % Use regular right-aligned column
\toprule
\textsc{Term} & {Df} & {$F$} & {$R^{2}$} & \multicolumn{1}{c}{$p$} \\  % Center the header
\midrule
Task complexity & 1 & 3.05 & 0.040 & $.029$ \\
Proficiency & 2 & 3.6806 & 0.097 & $.003$ \\
Task complexity $\times$ Proficiency & 2 & 0.75 & 0.020 & $.655$ \\
Residuals & 64 & & 0.843 & \\
Total & 69 & & 1.00 & \\
\bottomrule
\end{tabular}
\end{table}



\begin{figure}[t]
  \centering
  % Replace the filename below with your exported PCoA PDF (e.g., p1.pdf)
  \includegraphics[width=.9\linewidth]{Chapters/study1fig/p1.pdf}
  \caption{PCoA of Euclidean distances computed from the five z-scaled indicators; points are individual observations, crosses mark centroids, ellipses show 95\% normal contours by task complexity (low vs.\ high). Axes labels report percent variance explained.}
  \label{fig:pcoa}
\end{figure}

\begin{figure}[t]
  \centering
  % Replace the filename below with your exported PERMDISP-by-load PDF (e.g., p2.pdf)
  \includegraphics[width=.9\linewidth]{Chapters/study1fig/p2.pdf}
  \caption{Homogeneity of dispersion (PERMDISP): distance to centroid by task complexity. Medians and IQRs overlap across conditions, consistent with the non-significant dispersion test.}
  \label{fig:disp-load}
\end{figure}

Given the significant proficiency effect, we conducted pairwise PERMANOVAs with Bonferroni correction. The lower vs.\ upper contrast remained significant after correction ($p_{\text{adj}} = .003$), whereas lower vs.\ middle ($p_{\text{adj}} = .249$) and middle vs.\ upper ($p_{\text{adj}} = .555$) did not (Table~\ref{tab:pairwise}).


\begin{table}[htbp]
\centering
\footnotesize
\caption{Pairwise proficiency PERMANOVAs with Bonferroni adjusted $p$ values.}
\label{tab:pairwise}
\sisetup{
  input-signs = {},
  table-align-text-pre = false,
  table-align-text-post = false
}
\begin{tabular}{l
                S[table-format=1.2]
                S[table-format=0.3]
                l
                l}
\toprule
\textsc{Contrast} & {$F$} & {$R^{2}$} & {$p$} & {$p_{\text{Bonf}}$} \\
\midrule
{Lower vs Upper}  & 7.80 & 0.151 & $.001$ & $.003$ \\
{Lower vs Middle} & 2.15 & 0.047 & $.083$ & $.249$ \\
{Middle vs Upper} & 1.52 & 0.032 & $.185$ & $.555$ \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Discriminant Structure of Task Complexity}


As a descriptive follow up to the task complexity effect, LDA yielded a single discriminant dimension (proportion of trace $=1$ for two groups) that contrasted phrasal and temporal fluency (positive coefficients for content words per AS unit and speech rate) with lexical density (negative coefficient). Leave-one-out cross validation classified 60\% of cases correctly, with a modest separation between low and high complexity conditions (Figure~\ref{fig:lda-cm}). The discriminant coefficients are shown in Table~\ref{tab:lda-coef}. Box’s M was not significant ($\chi^{2}(15) = 21.603$, $p = .119$), which is consistent with the LDA covariance assumption in this sample.

\begin{figure}[t]
  \centering
  % Replace the filename below with your exported LDA confusion matrix PDF (e.g., p3.pdf)
  \includegraphics[width=.9\linewidth]{Chapters/study1fig/p3.pdf}
  \caption{LDA leave-one-out cross-validation confusion matrix. Cells show counts and row-wise percentages by true vs.\ predicted task complexity. Overall accuracy = 60\%.}
  \label{fig:lda-cm}
\end{figure}

\begin{table}[t]
\centering
\footnotesize
\caption{Linear discriminant coefficients (LD1). Positive values indicate higher scores on the fluency and phrasal side of the discriminant.}
\label{tab:lda-coef}
% Use 'S' column and set format for sign, 1 integer, 2 decimals
\begin{tabular}{l S[table-format=-1.2]}
\toprule
% Wrap S-column header in {}
\textsc{Predictor} & {LD1} \\
\midrule
Speech rate & 0.42 \\
Content words per AS-unit & 0.79 \\
Lexical density & -0.63 \\
Mid-clause pause duration (s) & -0.03 \\
Error rate (per AS-unit) & 0.07 \\
Proficiency (middle) & -0.78 \\
Proficiency (upper) & -1.49 \\
\bottomrule
\end{tabular}
\end{table}


\section{Discussion}

\subsection{Prioritization Patterns Under Cognitive Load}
Our research question asked how L2 learners prioritize and trade off complexity, accuracy, and fluency as cognitive load increases. The multivariate results show a reliable, although small, shift in the joint CAF profile from low to high complexity, with no moderation by proficiency. Reading the PERMANOVA alongside the LDA, learners under higher load prioritized lexical precision over phrasal elaboration and temporal speed; speech rate decreased and content words per AS unit declined, whereas lexical density increased, and accuracy was maintained. With respect to H1, the data support a coherent multivariate shift under higher load, with costs in temporal and phrasal fluency, and with protection of lexical precision and form reliability; no task complexity by proficiency interaction was observed.

This trade-off pattern is consistent with limited capacity views in which performance dimensions compete for attentional resources as demands rise, producing costs in speed and phrasal elaboration when resources are redirected to lexical selection and monitoring \parencite{Skehan2009}. At the same time, the findings nuance resource-directing perspectives developed in task-based research: increases in task complexity are often expected to raise “complexity,” but the present evidence indicates such changes are dimension-specific, not unitary \parencite{Robinson2005}. Framed within the resource-directing / resource dispersing distinction \parencite{levkina2012}, our manipulation recruited attention into message formulation and monitoring: phrasal complexity contracted while lexical density increased, a dissociation that helps explain mixed CAF outcomes reported across task types and implementations \parencite{chen2022}.

Proficiency explained additional variance independent of task complexity (with lower vs.\ upper differing), echoing reports that CAF reallocations vary systematically with learner characteristics \parencite{chen2022}. The absence of a task complexity by proficiency interaction indicates that increasing element interactivity shifted CAF profiles similarly across proficiency strata rather than amplifying or reversing group differences.


\subsection{Limitations, Implications, and Future Directions}


Methodologically, we validated the designed difference in task complexity as cognitively consequential via converging manipulation checks (subjective difficulty/effort, secondary-task speed/accuracy), in line with recommendations that such validation underwrite causal claims about downstream CAF differences \parencite{revesz2014,Lee2019}. Modeling CAF in a multivariate framework respects their covariance and avoids the interpretive pitfalls of separate univariate tests that can obscure trade-offs and inflate Type I error \parencite{ahmadian2012,tabari2016,qian2023,liuYeung2023,kuiken2007}. 

Several limitations warrant consideration. First, the secondary task, while serving as a manipulation check, may have diverted participants' attentional resources and potentially affected speech production \parencite{fukuta2015}; future research should consider alternative validation methods that do not interfere with the primary task. Second, the small effect size and reliance on a single argumentative matching task with trimmed samples (analyzing only the initial 60 seconds) may not fully capture participants' oral performance or generalize across task types; more comprehensive samples and diverse task designs are needed. Third, our homogeneous participant group and the omission of some linguistic features (e.g., phonetic predictors) limit generalizability. 

Pedagogically, increasing element interactivity can be used to probe or train lexical precision while anticipating costs in speed and phrasal density, without a systematic increase in overt errorfulness. Theoretically, the results underscore that task-induced “complexity” shifts are not unitary: under higher cognitive load, lexical and phrasal dimensions can diverge, a pattern consistent with limited capacity accounts and complementary to resource-directing predictions when complexity is decomposed by facet \parencite{Skehan2009,Robinson2005,levkina2012}. Over longer spans, sustained exposure to resource-directing demands may yield developmental benefits in syntactic complexity and fluency despite short-term trade-offs, suggesting a potential pathway for instruction and assessment \parencite{gilabert2007,kim2017}.


\section{Conclusion}
The present study asked how L2 speakers of Japanese prioritize and trade off complexity, accuracy, and fluency as cognitive load increases. The multivariate analyses showed a reliable, although small, shift in the joint CAF profile under higher task complexity. Learners protected lexical precision, indicated by increased lexical density, while accepting costs in temporal speed and phrasal elaboration, indicated by reduced speech rate and fewer content words per AS-unit. Accuracy did not decline. These reallocations were similar across proficiency strata, with overall level differences but no interaction with task complexity. In short, when demands rise, learners direct limited attention toward lexical selection and monitoring, and they ease off speed and phrasal packaging.

Methodologically, modeling CAF in a single multivariate framework recovered the allocation pattern that separate per-index tests might obscure. The design also incorporated independent validation of the complexity manipulation, which strengthens causal interpretation of downstream differences. At the same time, the effects were modest, the task type was narrow, and the productions were trimmed. Generality should be tested across genres, longer stretches of speech, and with richer process-proximal indicators such as repairs and repetitions.

For pedagogy and assessment, the results caution against treating complexity as a unitary outcome. Increases in element interactivity can pull lexical and phrasal dimensions in different directions, so tasks that aim to cultivate precise lexical choice may do so at the expense of speed and phrasal density, while not necessarily increasing overt errorfulness. This suggests two practical levers: use higher interactivity to probe or train lexical precision while explicitly supporting phrasal packaging, and evaluate speaking with composite profiles that respect trade offs rather than single indices in isolation.

Finally, these findings set up the next steps in the thesis. Subsequent studies examine whether analogous reallocations appear in comprehension. Together, this program moves from establishing allocation under load in production to linking performance profiles with evaluation.